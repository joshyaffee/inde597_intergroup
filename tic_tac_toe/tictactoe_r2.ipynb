{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8bf022f",
   "metadata": {},
   "source": [
    "# Tic Tac Toe - Round 2\n",
    "\n",
    "We expect an optimal tic tac toe player to never lose a game. However, Team B's dynamic programming (DP) model had a positive win rate against Team A's DP model when Team B played first. We attribute this to Team A only training on starting positions where Team A played first.\n",
    "\n",
    "In this version, Team A attempts a Q-Learning model that trains on going both first and second and on a variety of openings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92774a5e",
   "metadata": {},
   "source": [
    "# Summary of Outcomes\n",
    "\n",
    "Team B once again triumphs. Team A and Team B consistently tie when the starting position is the standard blank board. However, when certain random openings are forced, Team B has a positive win rate.\n",
    "\n",
    "We attribute the reason to be that Team B's DP model has seen every single game state, whereas Team A's Q-Learning model has only seen a subset of game states. When a random opening causes a strange game state that Team A does not recognize, Team A is prone to misplaying or playing an illegal move. Furthermore, the Team B DP model is much faster to train at this scale. Conclude that DP beats Q-Learning for a game of the scope of tic tac toe.\n",
    "\n",
    "However, after training the Team A Q-Learning model against the Team B DP model, the Q-Learning learns to play optimally. All games now result in ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d29b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set current working directory to \"inde597_intergroup\" (the outermost folder in the repository) for proper package imports\n",
    "os.chdir(\"C:/Users/georg/OneDrive/Documents/Rice University/Current Coursework/Inde597 Deep and Reinforcement Learning/Code/inde597_intergroup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429f08a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e3ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from environments import *\n",
    "\n",
    "class TicTacToe(EnvironmentVersus):\n",
    "    '''\n",
    "    Implements tic tac toe\n",
    "    States are stored as a 9-tuple of flags -1, 0, 1\n",
    "        1  agent 0 mark\n",
    "        -1 agent 1 mark\n",
    "        0  no mark\n",
    "    Actions are represented as an integer between 0 and 8, inclusive, indicating the index of the square to play in\n",
    "    '''\n",
    "    # Reward for illegal move\n",
    "    illegal_reward = -100\n",
    "    \n",
    "    # Container for all 8 ways to get 3 in a row\n",
    "    triples = ((0, 1, 2),\n",
    "               (3, 4, 5),\n",
    "               (6, 7, 8),\n",
    "               (0, 3, 6),\n",
    "               (1, 4, 7),\n",
    "               (2, 5, 8),\n",
    "               (0, 4, 8),\n",
    "               (2, 4, 6))\n",
    "    \n",
    "    def __init__(self, agents):\n",
    "        '''\n",
    "        Initialize this environment\n",
    "        INPUT\n",
    "            agents; 2-length Sequence of Agents\n",
    "        '''\n",
    "        if len(agents) != 2:\n",
    "            raise Exception(\"Expected 2 agents.\")\n",
    "        super().__init__(agents)\n",
    "    \n",
    "    def get_actions(self):\n",
    "        '''\n",
    "        RETURNS all possible moves\n",
    "        '''\n",
    "        return tuple(range(9))\n",
    "    \n",
    "    def step(self, action:int, agent_ind:int):\n",
    "        '''\n",
    "        Steps in the current game by marking the player move\n",
    "        Mutates self.current_state to be the next state\n",
    "        INPUT\n",
    "            action; action taken at this step\n",
    "            agent_ind; index of the agent who took this action\n",
    "        RETURNS 4 arguments\n",
    "            0: next state after the step\n",
    "            1: reward for the action\n",
    "            2: boolean flag whether the environment has terminated\n",
    "            3: the index of the agent whose turn it is\n",
    "        '''        \n",
    "        # If move is illegal, end the game with game loss penalty\n",
    "        if self.current_state[action] != 0:\n",
    "            return self.current_state, self.illegal_reward, True, None\n",
    "        \n",
    "        # Make appropriate mark\n",
    "        next_state = list(self.current_state)\n",
    "        if agent_ind == 0:\n",
    "            next_state[action] = 1\n",
    "        elif agent_ind == 1:\n",
    "            next_state[action] = -1\n",
    "        else:\n",
    "            raise Exception(\"Invalid agent_ind. Expected 0 or 1.\")\n",
    "        self.current_state = tuple(next_state)\n",
    "        \n",
    "        # Check for wins\n",
    "        for triple in self.triples:\n",
    "            line_sum = sum([self.current_state[cell] for cell in triple])\n",
    "            if (line_sum == 3 and agent_ind == 0) or (line_sum ==-3 and agent_ind == 1):\n",
    "                return self.current_state, 1, True, None\n",
    "        \n",
    "        # Check for tie\n",
    "        if 0 not in self.current_state:\n",
    "            return self.current_state, 0, True, None\n",
    "                \n",
    "        # Return\n",
    "        return self.current_state, 0, False, 1 - agent_ind\n",
    "        \n",
    "    def reset(self, opening=tuple([0] * 9)):\n",
    "        '''\n",
    "        Resets the board. If an opening is provided, resets the board to the opening state.\n",
    "        INPUT\n",
    "            opening; a tuple representing the opening state\n",
    "        RETURNS\n",
    "            the opening state\n",
    "        '''\n",
    "        self.current_state = opening\n",
    "        return self.current_state\n",
    "    \n",
    "    def reinterpret_state_for_agent(self, state, agent_ind):\n",
    "        '''\n",
    "        Remaps the 1 and -1 markings for the given indexed agent\n",
    "        INPUT\n",
    "            state; tuple representing board state\n",
    "            agent_ind; indexed agent\n",
    "        '''\n",
    "        if agent_ind == 0:\n",
    "            return state\n",
    "        elif agent_ind == 1:\n",
    "            return tuple([-val for val in state])\n",
    "        else:\n",
    "            raise Exception(\"Invalid agent_ind. Expected 0 or 1.\")\n",
    "        \n",
    "    def render(self, state=tuple([0] * 9), is_0_first=True):\n",
    "        '''\n",
    "        Prints the given state as a board\n",
    "        INPUT\n",
    "            state; 9-tuple representing the state\n",
    "            is_0_first; boolean if agent 0 is the first player\n",
    "        '''\n",
    "        markers = [\" \"] * 9\n",
    "        for ind, mark in enumerate(state):\n",
    "            match mark:\n",
    "                case 1:\n",
    "                    if is_0_first:\n",
    "                        markers[ind] = \"X\"\n",
    "                    else:\n",
    "                        markers[ind] = \"O\"\n",
    "                case -1:\n",
    "                    if is_0_first:\n",
    "                        markers[ind] = \"O\"\n",
    "                    else:\n",
    "                        markers[ind] = \"X\"\n",
    "                case 0:\n",
    "                    markers[ind] = \" \"\n",
    "        msg = f\"{markers[0]}|{markers[1]}|{markers[2]}\"\n",
    "        msg += \"\\n-----\"\n",
    "        msg += f\"\\n{markers[3]}|{markers[4]}|{markers[5]}\"\n",
    "        msg += \"\\n-----\"\n",
    "        msg += f\"\\n{markers[6]}|{markers[7]}|{markers[8]}\"\n",
    "        print()\n",
    "        print(msg)\n",
    "        print()\n",
    "        \n",
    "    def compute_game_end_reward(self, history:List, agent_ind:int):\n",
    "        '''\n",
    "        Computes the reward accrued by the given indexed agent at the end of the game\n",
    "        If given player was the last player to move, returns 0\n",
    "        If given player was the opponent of the last player to move, returns -1 if loss, 1 if won, and 1 if won by illegal move\n",
    "        INPUT\n",
    "            history; episode pathway as a list of 4-tuples, each of which has components:\n",
    "                0: state\n",
    "                1: action\n",
    "                2: reward\n",
    "                3: index of agent\n",
    "                The last element is the final state, given as (final_state, None, None, None)\n",
    "            agent_ind; integer index of the agent to compute the game end rewards for\n",
    "        RETURNS\n",
    "            amount by which to modify the reward of the last action made by the indexed agent\n",
    "        '''\n",
    "        # Check that the last element in the pathway is a final_state,\n",
    "        # indicated by None as the index of the agent\n",
    "        if history[-1][3] is not None:\n",
    "            raise Exception(\"The last episode pathway element had a non-None agent_ind, indicating the episode is not yet done.\")\n",
    "\n",
    "        # Get agent and reward of the last action\n",
    "        last_agent_ind = history[-2][3]\n",
    "        last_reward = history[-2][2]\n",
    "\n",
    "        # If the last agent and the given agent are the same, return 0\n",
    "        if last_agent_ind == agent_ind:\n",
    "            return 0\n",
    "        \n",
    "        # Return the negative of the reward gained by the last agent\n",
    "        if last_reward == self.illegal_reward:\n",
    "            return 1\n",
    "        else:\n",
    "            return -last_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac612b",
   "metadata": {},
   "source": [
    "# Train Team A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79c58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:49<00:00, 2031.78it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tic_tac_toe.team_a.temporal_difference import QLearning\n",
    "\n",
    "# Training parameters\n",
    "N_EPISODES = 10 ** 5\n",
    "PROB_RANDOM_OPENING = 0.8\n",
    "\n",
    "# Intialize the agent and environment\n",
    "team_a = QLearning(eps=0.2, gamma=1, alpha=0.5)\n",
    "train_game = TicTacToe((team_a, team_a))\n",
    "\n",
    "# Run training episodes on blank board. Track the ties over time to show progres.\n",
    "tie_list = []\n",
    "for _ in tqdm(range(N_EPISODES)):\n",
    "    \n",
    "    # Construct opening, with 0.5 probability of a random opening\n",
    "    first_agent_ind = np.random.choice(range(2))\n",
    "    random_opening = [0] * 9\n",
    "    if np.random.random() < PROB_RANDOM_OPENING:\n",
    "        random_opening[np.random.choice(range(9))] = -1 if first_agent_ind == 0 else 1\n",
    "    random_opening = tuple(random_opening)\n",
    "\n",
    "    # Play game\n",
    "    _, rewards = train_game.play_game((random_opening, first_agent_ind))\n",
    "    tie_list.append(int(rewards == [0, 0]))\n",
    "    \n",
    "# Plot the proportion of games played that are ties\n",
    "prop_tie = np.cumsum(tie_list) / (np.array(range(len(tie_list))) + 1)\n",
    "plt.plot(prop_tie)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Proportion of all games that have tied\")\n",
    "plt.title(\"Training progress\")\n",
    "plt.show()\n",
    "\n",
    "# Set the agent to all greedy\n",
    "team_a.eps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f57ad0",
   "metadata": {},
   "source": [
    "We expect an optimal player to tie every game against itself. The tie proportion is low because epsilon-greedy on-policy will often select illegal moves when exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b73ba7",
   "metadata": {},
   "source": [
    "# Train Team B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a00d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import numpy as np\n",
    "\n",
    "class envB:\n",
    "    \"\"\"\n",
    "    This class is used to define a tic tac toe environment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.previous_board = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.board = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        self.turn = 1\n",
    "        self.winner = 0\n",
    "\n",
    "    def reset(self, position = None):\n",
    "        if position is None:\n",
    "            position = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        if type(position) != list:\n",
    "            raise ValueError(\"The position must be a list of 9 elements\")\n",
    "        if len(position) != 9:\n",
    "            raise ValueError(\"The position must be a list of 9 elements\")\n",
    "        self.board = position\n",
    "        self.turn = 1\n",
    "        self.winner = 0\n",
    "        return self.board\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        This function is used to remove the last move\n",
    "        \"\"\"\n",
    "        self.board = self.previous_board\n",
    "        self.turn = -self.turn\n",
    "        self.winner = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        This function is used to make a move on the board\n",
    "        Returns:\n",
    "            - The new board\n",
    "            - The reward (0 if there is no winner)\n",
    "            - A boolean indicating if the game is finished\n",
    "        If the action is not possible, the game is forfeited with a reward of -10 * self.turn\n",
    "        \"\"\"\n",
    "        self.previous_board = self.board.copy()\n",
    "        if self.board[action] == 0:\n",
    "            self.board[action] = self.turn\n",
    "            self.turn = -self.turn\n",
    "            self.winner = self.check_winner()\n",
    "            done = self.winner != 0 or 0 not in self.board\n",
    "            return self.board, self.winner, done\n",
    "        else:\n",
    "            print(\"Invalid move!\")\n",
    "            print(self)\n",
    "            print(f\"Action: {action}\")\n",
    "            return self.board, -10 * self.turn, True\n",
    "\n",
    "    def check_winner(self, board = None):\n",
    "        \"\"\"\n",
    "        This function is used to check if there is a winner\n",
    "        \"\"\"\n",
    "        if board is None:\n",
    "            board = self.board\n",
    "        for i in range(3):\n",
    "            if board[i] == board[i + 3] == board[i + 6] != 0:\n",
    "                return board[i]\n",
    "            if board[i * 3] == board[i * 3 + 1] == board[i * 3 + 2] != 0:\n",
    "                return board[i * 3]\n",
    "        if board[0] == board[4] == board[8] != 0:\n",
    "            return board[0]\n",
    "        if board[2] == board[4] == board[6] != 0:\n",
    "            return board[2]\n",
    "        if 0 not in board:\n",
    "            return 0\n",
    "        return 0\n",
    "    \n",
    "    def get_actions(self):\n",
    "        \"\"\"\n",
    "        This function is used to get the possible actions\n",
    "        \"\"\"\n",
    "        return [i for i in range(9) if self.board[i] == 0]\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        This function is used to print the board\n",
    "        \"\"\"\n",
    "        symbols = {0: \" \", 1: \"X\", -1: \"O\"}\n",
    "        return f\"{symbols[self.board[0]]}|{symbols[self.board[1]]}|{symbols[self.board[2]]}\\n-----\\n{symbols[self.board[3]]}|{symbols[self.board[4]]}|{symbols[self.board[5]]}\\n-----\\n{symbols[self.board[6]]}|{symbols[self.board[7]]}|{symbols[self.board[8]]}\"\n",
    "    \n",
    "class AgentB():\n",
    "    \"\"\"\n",
    "    This class is used to define a tic tac toe agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.init_policy()\n",
    "\n",
    "    def init_policy(self):\n",
    "        \"\"\"\n",
    "        This function is used to initialize the policy\n",
    "        \"\"\"\n",
    "        self.s_plus, self.s = enumerate_states()\n",
    "        self.terminals = {s for s in self.s_plus if s not in self.s}\n",
    "        self.values = {}\n",
    "        self.policy = {}\n",
    "\n",
    "        # initialize the values of the terminal states to 0\n",
    "        # initialize the policy to random and value to arbitrary value for the non\n",
    "        # terminal states\n",
    "        for state in self.s_plus:\n",
    "            if state in self.s:\n",
    "                self.values[state] = .1\n",
    "                self.policy[state] = 0\n",
    "            else:\n",
    "                self.values[state] = 0\n",
    "\n",
    "        print(\"Initialization done!\")\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        This function is used to get the value of a state\n",
    "        \"\"\"\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.values:\n",
    "                return self.values[tuple(iso)]\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "    \n",
    "    def get_policy(self, state):\n",
    "        e = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        r1 = [2, 5, 8, 1, 4, 7, 0, 3, 6]\n",
    "        r2 = [8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "        r3 = [6, 3, 0, 7, 4, 1, 8, 5, 2]\n",
    "        s = [2, 1, 0, 5, 4, 3, 8, 7, 6]\n",
    "        sr1 = [0, 3, 6, 1, 4, 7, 2, 5, 8]\n",
    "        sr2 = [6, 7, 8, 3, 4, 5, 0, 1, 2]\n",
    "        sr3 = [8, 5, 2, 7, 4, 1, 6, 3, 0]\n",
    "        symmetries = [e, r1, r2, r3, s, sr1, sr2, sr3]\n",
    "\n",
    "        for s, iso in enumerate(get_isomorphisms(state)):\n",
    "            if tuple(iso) in self.policy:\n",
    "                # the symmetry\n",
    "                sym = symmetries[s]\n",
    "                return sym[self.policy[tuple(iso)]]\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "            \n",
    "    def set_value(self, state, value):\n",
    "        \"\"\"\n",
    "        This function is used to set the value of a state\n",
    "        \"\"\"\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.values:\n",
    "                self.values[tuple(iso)] = value\n",
    "                return True\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "        \n",
    "    def set_policy(self, state, action):\n",
    "        for iso in get_isomorphisms(state):\n",
    "            if tuple(iso) in self.policy:\n",
    "                self.policy[tuple(iso)] = action\n",
    "                return True\n",
    "        else:\n",
    "            raise ValueError(\"The state is not in the state space\")\n",
    "       \n",
    "    def value_iteration(self, gamma = 1, theta = 1e-5):\n",
    "        delta = np.inf\n",
    "        while delta > theta:\n",
    "            delta = 0\n",
    "            for state in tqdm.tqdm(self.s):\n",
    "                self.env.reset(list(state))\n",
    "                old_v = self.get_value(state)\n",
    "                v = - np.inf\n",
    "                for action in self.env.get_actions():\n",
    "                    next_state, reward, done = self.env.step(action)\n",
    "                    v = max(v, reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state)))\n",
    "                    self.env.pop()\n",
    "                self.set_value(state, v)\n",
    "                delta = max(delta, abs(old_v - v))\n",
    "        \n",
    "        # output policy according to the value function\n",
    "        for state in self.s:\n",
    "            self.env.reset(list(state))\n",
    "            v = - np.inf\n",
    "            for action in self.env.get_actions():\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "                if reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state)) > v:\n",
    "                    v = reward + gamma * -1 * self.get_value(tuple(-1 * i for i in next_state))\n",
    "                    best_action = action\n",
    "                self.env.pop()\n",
    "            self.set_policy(state, best_action)\n",
    "\n",
    "    def train(self, gamma = .9, theta = 1e-5):\n",
    "        self.value_iteration(gamma, theta)\n",
    "        print(\"Value iteration done!\")\n",
    "\n",
    "    def self_test(self):\n",
    "        \"\"\"\n",
    "        This function is used to test the agent\n",
    "        \"\"\"\n",
    "        self.env.reset()\n",
    "        print(self.env)\n",
    "        state = self.env.board\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = self.get_policy(tuple(state))\n",
    "            state, _, done = self.env.step(action)\n",
    "            state = [-1 * i for i in state]\n",
    "            print(self.env)\n",
    "            print()\n",
    "        if self.env.check_winner() == 0:\n",
    "            print(\"It's a draw!\")\n",
    "        elif self.env.check_winner() == 1:\n",
    "            print(\"X wins!\")\n",
    "        else:\n",
    "            print(\"O wins!\")\n",
    "    \n",
    "    def play_random(self, n=10000):\n",
    "        \"\"\"\n",
    "        This function is used to play random games\n",
    "        \"\"\"\n",
    "        Xwins = 0\n",
    "        Xdraws = 0\n",
    "        Xlosses = 0\n",
    "\n",
    "        Owins = 0\n",
    "        Odraws = 0\n",
    "        Olosses = 0\n",
    "        for game in tqdm.tqdm(range(n)):\n",
    "            symbol = game % 2 * 2 - 1\n",
    "\n",
    "            self.env.reset()\n",
    "            state = self.env.board\n",
    "            done = False\n",
    "            while not done:\n",
    "                if symbol == self.env.turn:\n",
    "                    action = self.get_policy(tuple(state))\n",
    "                else:\n",
    "                    action = np.random.choice(self.env.get_actions())\n",
    "                state, _, done = self.env.step(action)\n",
    "                state = [-1 * i for i in state]\n",
    "            \n",
    "            if self.env.check_winner() == 0:\n",
    "                if symbol == 1:\n",
    "                    Xdraws += 1\n",
    "                else:\n",
    "                    Odraws += 1\n",
    "            elif self.env.check_winner() == symbol:\n",
    "                if symbol == 1:\n",
    "                    Xwins += 1\n",
    "                else:\n",
    "                    Owins += 1\n",
    "            else:\n",
    "                if symbol == 1:\n",
    "                    Xlosses += 1\n",
    "                else:\n",
    "                    Olosses += 1\n",
    "        print(f\"for X: wins = {Xwins}, draws = {Xdraws}, losses = {Xlosses}\")\n",
    "        print(f\"for O: wins = {Owins}, draws = {Odraws}, losses = {Olosses}\")\n",
    "        return Xwins, Xdraws, Xlosses, Owins, Odraws, Olosses\n",
    "\n",
    "def check_symmetry(board1, board2):\n",
    "    if board1 in get_isomorphisms(board2):\n",
    "        return True\n",
    "        \n",
    "\n",
    "def get_isomorphisms(board):\n",
    "    e = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    r1 = [2, 5, 8, 1, 4, 7, 0, 3, 6]\n",
    "    r2 = [8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "    r3 = [6, 3, 0, 7, 4, 1, 8, 5, 2]\n",
    "    s = [2, 1, 0, 5, 4, 3, 8, 7, 6]\n",
    "    sr1 = [0, 3, 6, 1, 4, 7, 2, 5, 8]\n",
    "    sr2 = [6, 7, 8, 3, 4, 5, 0, 1, 2]\n",
    "    sr3 = [8, 5, 2, 7, 4, 1, 6, 3, 0]\n",
    "    symmetries = [e, r1, r2, r3, s, sr1, sr2, sr3]\n",
    "    return [[board[i] for i in symmetry] for symmetry in symmetries]\n",
    "\n",
    "\n",
    "def enumerate_states():\n",
    "    \"\"\"\n",
    "    This function is used to enumerate all the possible states  and corresponding actions of the tic tac toe game\n",
    "    UPTO ISOMORPHISM\n",
    "\n",
    "    1 indicates agent's symbol when it's their turn so the number of 1s is at least the number of -1s minus 1\n",
    "    and at most the number of -1s\n",
    "    \"\"\"\n",
    "    isomorphic_boards = {}\n",
    "    non_terminal = set()\n",
    "    for i in range(3 ** 9):\n",
    "        board = []\n",
    "        for j in range(9):\n",
    "            board.append((i // (3 ** j)) % 3 - 1)\n",
    "        if board.count(1) < board.count(-1) - 1 or board.count(1) > board.count(-1):\n",
    "            continue\n",
    "        iso = False\n",
    "        if (board.count(1), board.count(-1)) not in isomorphic_boards:\n",
    "            isomorphic_boards[(board.count(1), board.count(-1))] = []\n",
    "\n",
    "        for ib in isomorphic_boards[(board.count(1), board.count(-1))]:\n",
    "            if check_symmetry(board, ib):\n",
    "                iso = True\n",
    "                break\n",
    "        if iso:\n",
    "            continue\n",
    "        \n",
    "        # check that the board is valid (i.e. if both players have 3 in a row, the board\n",
    "        # is invalid)\n",
    "        \n",
    "        winners = num_winners(board)\n",
    "        if winners > 1: \n",
    "            continue\n",
    "        if winners == 0 and board.count(0) > 0:\n",
    "            non_terminal.add(tuple(board))\n",
    "        \n",
    "        isomorphic_boards[(board.count(1), board.count(-1))].append(board)\n",
    "\n",
    "    s_plus = set()\n",
    "    for k, v in isomorphic_boards.items():\n",
    "        for board in v:\n",
    "            s_plus.add(tuple(board))\n",
    "    s = non_terminal\n",
    "    return s_plus, s\n",
    "\n",
    "def num_winners(board):\n",
    "    winners = set()\n",
    "    for i in range(3):\n",
    "        if board[i] == board[i + 3] == board[i + 6] != 0:\n",
    "            winners.add(board[i])\n",
    "        if board[i * 3] == board[i * 3 + 1] == board[i * 3 + 2] != 0:\n",
    "            winners.add(board[i * 3])\n",
    "        if board[0] == board[4] == board[8] != 0:\n",
    "            winners.add(board[0])\n",
    "        if board[2] == board[4] == board[6] != 0:\n",
    "            winners.add(board[2])\n",
    "    return len(winners)\n",
    "\n",
    "def display_policy(agent, board):\n",
    "    move = agent.get_policy(tuple(board))\n",
    "    if board[move] == 0:\n",
    "        board[move] = 10\n",
    "    else:\n",
    "        raise ValueError(\"The move is not possible: \" + str(move))\n",
    "    symbols = {0: \" \", 1: \"X\", -1: \"O\", 10: \"*\"}\n",
    "    print( f\"{symbols[board[0]]}|{symbols[board[1]]}|{symbols[board[2]]}\\n-----\\n{symbols[board[3]]}|{symbols[board[4]]}|{symbols[board[5]]}\\n-----\\n{symbols[board[6]]}|{symbols[board[7]]}|{symbols[board[8]]}\")\n",
    "    \n",
    "class WrapAgentB(Agent):\n",
    "    \n",
    "    mdl = None # the model trained on Team B technology\n",
    "    \n",
    "    def __init__(self, mdl):\n",
    "        '''\n",
    "        Sets model\n",
    "        '''\n",
    "        self.mdl = mdl\n",
    "    \n",
    "    def play(self, state):\n",
    "        return self.mdl.get_policy(list(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e27fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 10992.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 13430.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 11010.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 10426.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 11901.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 11293.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 627/627 [00:00<00:00, 11107.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tic_tac_toe = envB()\n",
    "B = AgentB(tic_tac_toe)\n",
    "B.train()\n",
    "\n",
    "team_b = WrapAgentB(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7891f17",
   "metadata": {},
   "source": [
    "# Play games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e574d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make environment\n",
    "test_game = TicTacToe((team_a, team_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248f74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A played first.\n",
      "Tie.\n",
      "\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "\n",
      "\n",
      " | |X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "\n",
      "\n",
      " | |X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "\n",
      "\n",
      "X| |X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " |X| \n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "O|X| \n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      "X|O| \n",
      "-----\n",
      "O|X| \n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      "X|O| \n",
      "-----\n",
      "O|X|O\n",
      "\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      "O|X|O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get game outcome\n",
    "history, rewards = test_game.play_game()\n",
    "\n",
    "# Victor\n",
    "if history[0][3] == 0:\n",
    "    print(\"A played first.\")\n",
    "    first_agent_ind = 0\n",
    "else:\n",
    "    print(\"B played first.\")\n",
    "    first_agent_ind = 1\n",
    "\n",
    "# Outcome\n",
    "if rewards[0] > rewards[1]:\n",
    "    print(\"A won.\")\n",
    "elif rewards[1] > rewards[0]:\n",
    "    print(\"B won.\")\n",
    "else:\n",
    "    print(\"Tie.\")\n",
    "\n",
    "# Render\n",
    "for state, _, _, _ in history:\n",
    "    test_game.render(state, 1 - first_agent_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88129b7",
   "metadata": {},
   "source": [
    "Make 10 openings: the blank board, plus each of the 9 first moves.\n",
    "\n",
    "For each opening, play 20 games, where each agent plays first for 10 of those games.\n",
    "\n",
    "Record wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c538e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 0, 0, 0, 0, 0) 0\n",
      "(-1, 0, 0, 0, 0, 0, 0, 0, 0) 0\n",
      "(0, -1, 0, 0, 0, 0, 0, 0, 0) 0\n",
      "(0, 0, -1, 0, 0, 0, 0, 0, 0) 0\n",
      "(0, 0, 0, -1, 0, 0, 0, 0, 0) 0\n",
      "(0, 0, 0, 0, -1, 0, 0, 0, 0) 0\n",
      "(0, 0, 0, 0, 0, -1, 0, 0, 0) 0\n",
      "(0, 0, 0, 0, 0, 0, -1, 0, 0) 0\n",
      "(0, 0, 0, 0, 0, 0, 0, -1, 0) 0\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, -1) 0\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0) 1\n",
      "(1, 0, 0, 0, 0, 0, 0, 0, 0) 1\n",
      "(0, 1, 0, 0, 0, 0, 0, 0, 0) 1\n",
      "(0, 0, 1, 0, 0, 0, 0, 0, 0) 1\n",
      "(0, 0, 0, 1, 0, 0, 0, 0, 0) 1\n",
      "(0, 0, 0, 0, 1, 0, 0, 0, 0) 1\n",
      "(0, 0, 0, 0, 0, 1, 0, 0, 0) 1\n",
      "(0, 0, 0, 0, 0, 0, 1, 0, 0) 1\n",
      "(0, 0, 0, 0, 0, 0, 0, 1, 0) 1\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 1) 1\n"
     ]
    }
   ],
   "source": [
    "# Make openings where agent 0 plays first\n",
    "first_agent_inds = [0]\n",
    "openings = [[0] * 9]\n",
    "for ind in range(9):\n",
    "    openings.append([0] * 9)\n",
    "    openings[-1][ind] = -1\n",
    "    first_agent_inds.append(0)\n",
    "    \n",
    "# Make openings where agent 1 plays first\n",
    "openings.extend([[-mark for mark in opening] for opening in openings])\n",
    "first_agent_inds.extend([1] * 10)\n",
    "\n",
    "# Tuple\n",
    "openings = [tuple(opening) for opening in openings] \n",
    "_ = [print(opening, first_ind) for opening, first_ind in zip(openings, first_agent_inds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61222d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (-1, 0, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 4. Tie: 6\n",
      "\n",
      "Opening (0, -1, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 8. Tie: 2\n",
      "\n",
      "Opening (0, 0, -1, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 5. Tie: 5\n",
      "\n",
      "Opening (0, 0, 0, -1, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 3. Tie: 7\n",
      "\n",
      "Opening (0, 0, 0, 0, -1, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 10. Tie: 0\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, -1, 0, 0, 0). A plays first.\n",
      "A: 0. B: 2. Tie: 8\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, -1, 0, 0). A plays first.\n",
      "A: 0. B: 10. Tie: 0\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, -1, 0). A plays first.\n",
      "A: 0. B: 10. Tie: 0\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, -1). A plays first.\n",
      "A: 0. B: 10. Tie: 0\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 7. Tie: 3\n",
      "\n",
      "Opening (1, 0, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 1, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 1, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 1, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 1, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 1, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 1, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 1, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 1). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_TRIAL = 10\n",
    "for opening, first_ind in zip(openings, first_agent_inds):\n",
    "    print(f\"Opening {opening}. {'A' if first_ind == 0 else 'B'} plays first.\")\n",
    "    a_win = 0\n",
    "    b_win = 0\n",
    "    tie = 0\n",
    "    for _ in range(N_TRIAL):\n",
    "        history, rewards = test_game.play_game((opening, first_ind))\n",
    "        if rewards[0] > rewards[1]:\n",
    "            a_win += 1\n",
    "        elif rewards[0] < rewards[1]:\n",
    "            b_win += 1\n",
    "        else:\n",
    "            tie += 1\n",
    "    print(f\"A: {a_win}. B: {b_win}. Tie: {tie}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da79bc",
   "metadata": {},
   "source": [
    "# Train the Team A Q-Learning against the Team B\n",
    "Run 10^3 episodes against each opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010240cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2361.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2770.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2719.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2712.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2534.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2609.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2681.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2646.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2580.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2849.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2605.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2590.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2943.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2774.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2461.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2707.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2689.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2601.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2449.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2681.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "N_TRIAL = 10 ** 3\n",
    "for opening, first_ind in zip(openings, first_agent_inds):\n",
    "    for _ in tqdm(range(N_TRIAL)):\n",
    "        _ = test_game.play_game((opening, first_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2449c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (-1, 0, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, -1, 0, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, -1, 0, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, -1, 0, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, -1, 0, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, -1, 0, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, -1, 0, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, -1, 0). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, -1). A plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (1, 0, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 1, 0, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 1, 0, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 1, 0, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 1, 0, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 1, 0, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 1, 0, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 1, 0). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n",
      "Opening (0, 0, 0, 0, 0, 0, 0, 0, 1). B plays first.\n",
      "A: 0. B: 0. Tie: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Play the games again\n",
    "\n",
    "N_TRIAL = 10\n",
    "for opening, first_ind in zip(openings, first_agent_inds):\n",
    "    print(f\"Opening {opening}. {'A' if first_ind == 0 else 'B'} plays first.\")\n",
    "    a_win = 0\n",
    "    b_win = 0\n",
    "    tie = 0\n",
    "    for _ in range(N_TRIAL):\n",
    "        history, rewards = test_game.play_game((opening, first_ind))\n",
    "        if rewards[0] > rewards[1]:\n",
    "            a_win += 1\n",
    "        elif rewards[0] < rewards[1]:\n",
    "            b_win += 1\n",
    "        else:\n",
    "            tie += 1\n",
    "    print(f\"A: {a_win}. B: {b_win}. Tie: {tie}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335f0ec",
   "metadata": {},
   "source": [
    "After training the Team A Q-Learning against the Team B DP, the Q-Learning learns how to play optimally. All games now result in ties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_inde597",
   "language": "python",
   "name": ".venv_inde597"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
